% RESEARCH EXPERIENCE â€” edit content only
% \Entry = role for ATS header; \SubSection = project grouping for designed CV
% \Description = optional paragraph below the entry header
% Dates: "Mon Year -- Mon Year" (e.g., "Sep 2024 -- Present")

\Entry{MSc Researcher --- AI and Digital Health}
    {University of Westminster}
    {Sep 2024 -- Present}
    {London, UK}
\Description{Integrated platform for ingesting, structuring, validating, and indexing scientific literature at scale. Designed as a single deterministic system with reproducibility, provenance, and hardware efficiency as architectural requirements.}

\SubSection{Platform Architecture \& Orchestration}
\begin{bullets}
    \Bullet{23-stage deterministic pipeline orchestrated via Prefect with distributed execution through RabbitMQ worker queues and hardware-aware compute profiles}
    \Bullet{6,636 documents / 100,034 pages at 99.91\% success, producing contract-valid structured JSON with full provenance (manifests, hashing, structured logging, stage-level contracts)}
    \Bullet{Sustained dual NVIDIA B200 GPUs at 90--96\% utilisation and CPUs at 56--65\% for 52 continuous hours, generating \textasciitilde1 TB across 2 million files with zero pipeline failure}
    \BulletLast{181 Docker containers and 11 NLP models concurrently; all hyperparameters grid-searched with confusion matrix validation for high F1. No models fine-tuned---performance achieved through architectural discipline}
\end{bullets}

\SubSection{Ontology \& Search Layer}
\begin{bullets}
    \Bullet{Parsed and normalised biomedical ontologies (MONDO, HPO, EFO) into queryable graph structures (DuckDB) for defensible disease labelling and filtering}
    \BulletLast{Parallel-processing ETL to index semantically chunked documents and extracted entities into Elasticsearch and PostgreSQL for high-recall retrieval and analytics}
\end{bullets}

\SubSection{Human-in-the-Loop Validation \& Quality Assurance}
\begin{bullets}
    \Bullet{SapBERT embedding similarity to propose and rank candidate feature aliases, with Flask application serving ML-ranked suggestions for expert approval/rejection}
    \Bullet{Evaluation methodology using stratified sampling and confusion matrices to quantify extraction and linking accuracy and guide thresholding}
    \BulletLast{Outputs feed verified training datasets for downstream model evaluation---closing the loop from raw document to validated, reusable knowledge}
\end{bullets}

\SubSection{UK Biobank Large-Scale Data Extraction}
\begin{bullets}
    \Bullet{Faculty stated extracting the full UK Biobank feature set across the 500,000-participant cohort was impossible. Read the entire DNA Nexus manual and identified a viable extraction path}
    \Bullet{Actual feature space was approximately 50,000 (not the assumed 10,000) including all arrays and instances. Pulled the complete dataset---50,000 features \texttimes\ 500,000 participants---into 15 parquet files totalling 42 GB}
    \BulletLast{Optimised extraction from 15 hours to 30 minutes---a 30\texttimes\ improvement through architectural understanding of the platform, not brute compute}
\end{bullets}
